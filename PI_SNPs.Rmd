---
title: "PI_SNPs"
author: "Dhanashri Kalyanasundaram"
date: "2025-08-29"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=TRUE}
library(dplyr)
library(stringr)
library(readr)

# Pick your Library_Genotypes.csv
lib_path <- file.choose()
lib <- read.csv(lib_path, stringsAsFactors = FALSE, check.names = FALSE)

# Identify meta columns (handle dots/percents from read.csv name conversion)
meta_candidates <- c("Sample", "Raw Reads", "On-Target Reads", "%On-Target", "%GT",
                     "Raw.Reads","On.Target.Reads","X.On.Target","X.GT")
meta_cols <- intersect(names(lib), meta_candidates)

# Locus columns = everything else
locus_cols <- setdiff(names(lib), meta_cols)

# Drop any all-empty locus columns (just in case)
is_all_empty <- function(x) all(is.na(x) | x == "" | x == "0")
locus_cols <- locus_cols[!vapply(lib[locus_cols], is_all_empty, logical(1))]

length(locus_cols)  # how many loci found


```
```{r, echo=TRUE}
calc_PI_from_column <- function(g) {
  # g: character vector like "AA", "AG", "CT", "0", "" ...
  g <- toupper(trimws(g))
  ok <- nchar(g) == 2 & grepl("^[ACGT][ACGT]$", g)
  if (!any(ok)) {
    return(list(N=0, alleles_used=NA_character_, p=NA_real_, q=NA_real_,
                PI=NA_real_, PID_sibs=NA_real_))
  }
  g2 <- g[ok]
  # split to two alleles per genotype
  a1 <- substr(g2, 1, 1)
  a2 <- substr(g2, 2, 2)
  all_alleles <- c(a1, a2)
  tab <- sort(table(all_alleles), decreasing = TRUE)

  if (length(tab) == 1) {
    # monomorphic
    p <- 1.0; q <- 0.0
    PI <- 1.0
    S2 <- p^2 + q^2; S4 <- p^4 + q^4
    PID_sibs <- 0.25 + 0.5*S2 + 0.5*(S2^2) - 0.25*S4
    return(list(N=length(g2), alleles_used=paste(names(tab), collapse="/"),
                p=p, q=q, PI=PI, PID_sibs=PID_sibs))
  }

  # take the two most common alleles as the bi-allelic set
  a_major <- names(tab)[1]
  a_minor <- names(tab)[2]
  keep <- (a1 %in% c(a_major, a_minor)) & (a2 %in% c(a_major, a_minor))
  if (!any(keep)) {
    return(list(N=0, alleles_used=paste(a_major, a_minor, sep="/"),
                p=NA_real_, q=NA_real_, PI=NA_real_, PID_sibs=NA_real_))
  }

  # count the two alleles among kept genotypes (diploid → 2 counts per sample)
  a1k <- a1[keep]; a2k <- a2[keep]
  n_major <- sum(a1k == a_major) + sum(a2k == a_major)
  n_minor <- sum(a1k == a_minor) + sum(a2k == a_minor)
  n_tot   <- n_major + n_minor
  if (n_tot == 0) {
    return(list(N=sum(keep), alleles_used=paste(a_major, a_minor, sep="/"),
                p=NA_real_, q=NA_real_, PI=NA_real_, PID_sibs=NA_real_))
  }

  # Let p = freq(minor), q = 1-p  (choice doesn’t matter for PI)
  p <- n_minor / n_tot
  p <- min(max(p, 1e-6), 1-1e-6)  # clamp away from 0/1
  q <- 1 - p

  PI <- p^4 + (2*p*q)^2 + q^4
  S2 <- p^2 + q^2
  S4 <- p^4 + q^4
  PID_sibs <- 0.25 + 0.5*S2 + 0.5*(S2^2) - 0.25*S4

  list(N=sum(keep), alleles_used=paste(a_major, a_minor, sep="/"),
       p=p, q=q, PI=PI, PID_sibs=PID_sibs)
}

# Apply across loci
per_locus <- lapply(locus_cols, function(col) {
  res <- calc_PI_from_column(lib[[col]])
  data.frame(Locus = col,
             N = res$N,
             Alleles = res$alleles_used,
             p = res$p, q = res$q,
             PI = res$PI,
             PID_sibs = res$PID_sibs)
})
pi_table <- bind_rows(per_locus)

# Keep loci with a valid PI
pi_table_valid <- pi_table %>% filter(is.finite(PI))
cat("Total loci:", nrow(pi_table), "\nValid PI loci:", nrow(pi_table_valid), "\n")
head(pi_table_valid, 10)


```
```{r, echo=TRUE}
set.seed(123)
K <- c(10, 20, 30, 40, 50, 60)
B <- 1000

PI_vec       <- pi_table_valid$PI
PIDs_vec     <- pi_table_valid$PID_sibs
L            <- length(PI_vec)

res <- lapply(K, function(k) {
  if (k > L) {
    return(data.frame(k=k, PI_median=NA, PI_q05=NA, PI_q95=NA,
                      PIDs_median=NA, PIDs_q05=NA, PIDs_q95=NA, Loci_available=L))
  }
  picks <- replicate(B, sample.int(L, k, replace = FALSE))
  PI_prod   <- apply(picks, 2, function(ix) prod(PI_vec[ix]))
  PIDs_prod <- apply(picks, 2, function(ix) prod(PIDs_vec[ix]))
  data.frame(
    k = k, Loci_available = L,
    PI_median   = median(PI_prod),
    PI_q05      = quantile(PI_prod, 0.05),
    PI_q95      = quantile(PI_prod, 0.95),
    PIDs_median = median(PIDs_prod),
    PIDs_q05    = quantile(PIDs_prod, 0.05),
    PIDs_q95    = quantile(PIDs_prod, 0.95)
  )
})

pi_summary <- bind_rows(res)
pi_summary


```
```{r, echo=TRUE}
out_dir <- getwd()  # change if you want
readr::write_csv(pi_table,   file.path(out_dir, "PI_per_locus.csv"))
readr::write_csv(pi_summary, file.path(out_dir, "PI_multilocus_resampled.csv"))
cat("Saved:\n- ", file.path(out_dir, "PI_per_locus.csv"),
    "\n- ", file.path(out_dir, "PI_multilocus_resampled.csv"), "\n", sep="")

# Quick visual (unrelated PI; median across resamples)
plot(pi_summary$k, pi_summary$PI_median, type="b", pch=16,
     xlab="Number of SNPs (k)", ylab="Multilocus PI (median)",
     main="Probability of Identity vs number of SNPs")

# Optional: siblings (more conservative)
plot(pi_summary$k, pi_summary$PIDs_median, type="b", pch=16,
     xlab="Number of SNPs (k)", ylab="Multilocus PID-sibs (median)",
     main="PID(sibs) vs number of SNPs")


```
```{r, echo=TRUE}
# Load required libraries
library(ggplot2)
library(dplyr)
```

```{r, echo=TRUE}
# ---- Load your PI summary table ----
# Either read from CSV or copy your table as a data.frame
pi_data <- read.csv("C:/Users/xh24541/OneDrive - University of Bristol/Microsoft Copilot Chat Files/Documents/PI_multilocus_resampled.csv")  # <-- Replace with your file path

# Convert from wide to long format for plotting
pi_long <- pi_data %>%
  select(k, PI_median, PIDs_median) %>%
  pivot_longer(cols = c(PI_median, PIDs_median),
               names_to = "Metric", values_to = "Value")

# ---- Plot: PI vs number of SNPs ----
ggplot(pi_long, aes(x = k, y = Value, color = Metric, group = Metric)) +
  geom_line(size = 1.2) +
  geom_point(size = 3) +
  scale_y_log10() +  # Log scale for better visualization of small PI
  scale_color_manual(values = c("PI_median" = "#1b9e77",   # Green
                                "PIDs_median" = "#d95f02")) + # Orange
  labs(title = "Probability of Identity vs Number of SNPs",
       x = "Number of SNPs (k)",
       y = "Probability of Identity (log scale)",
       color = "Metric") +
  theme_minimal(base_size = 14) +
  theme(legend.position = "top",
        plot.title = element_text(hjust = 0.5, face = "bold"))


```
```{r, echo=TRUE}
# 1) Load your multilocus PI table
#    (columns: k, Loci_available, PI_median, PI_q05, PI_q95, PIDs_median, PIDs_q05, PIDs_q95)
pi_multi <- read_csv("PI_multilocus_resampled.csv", show_col_types = FALSE)

# 2) Long format for ggplot
pi_long <- pi_multi %>%
  transmute(
    k = k,
    PI_median, PI_q05, PI_q95,
    PIDs_median, PIDs_q05, PIDs_q95
  ) %>%
  pivot_longer(
    cols = -k,
    names_to = c("Metric", ".value"),
    names_pattern = "(PI|PIDs)_(median|q05|q95)"
  ) %>%
  mutate(Metric = recode(Metric,
                         "PI"   = "Unrelated (PI)",
                         "PIDs" = "Siblings (PID-sibs)"))

# 3) Plot with ribbons (95% intervals) on log10 y-axis
p <- ggplot(pi_long, aes(x = k, y = median, color = Metric, fill = Metric, group = Metric)) +
  geom_ribbon(aes(ymin = q05, ymax = q95), alpha = 0.15, linewidth = 0) +
  geom_line(linewidth = 1.2) +
  geom_point(size = 3) +
  scale_y_log10() +
  scale_x_continuous(breaks = pi_multi$k) +
  scale_color_manual(values = c("Unrelated (PI)" = "#1b9e77", "Siblings (PID-sibs)" = "#d95f02")) +
  scale_fill_manual(values  = c("Unrelated (PI)" = "#1b9e77", "Siblings (PID-sibs)" = "#d95f02")) +
  labs(title = "Probability of Identity vs Number of SNPs",
       subtitle = "Lines show median; shaded bands show 5–95% range from resampling loci",
       x = "Number of SNPs (k)",
       y = "Probability (log scale)",
       color = NULL, fill = NULL) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "top",
        plot.title = element_text(face = "bold", hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

p

# 4) (Optional) Save high-res image for your report
ggsave("PI_vs_k_with_CI.png", plot = p, width = 7.5, height = 5.0, dpi = 300)

```
```{r,echo=TRUE}
# Assuming sibs_all has at least: ID, sibship_id
sibship_summary <- sibs_all %>%
  group_by(sibship_id) %>%
  summarise(n_members = n(), .groups = "drop") %>%
  mutate(Type = case_when(
    n_members == 1 ~ "Singleton",
    n_members == 2 ~ "Pair",
    n_members > 2  ~ "Group"
  ))

# Count totals by type
sibship_counts <- sibship_summary %>%
  group_by(Type) %>%
  summarise(Total = n(), .groups = "drop")

sibship_counts

```


```{r, echo=TRUE}

library(adegenet)

# Convert your SNP matrix to genind object (0/1/2 coding assumed)
geno_mat <- as.matrix(geno_num_all)  # rows = samples, cols = loci
genind_obj <- df2genind(geno_mat, ploidy = 2, type = "codom", sep = "")

# Calculate heterozygosity
Hs <- summary(genind_obj)$Hexp   # Expected heterozygosity per locus
Ho <- summary(genind_obj)$Hobs   # Observed heterozygosity per locus

heterozygosity_df <- data.frame(
  Locus = colnames(geno_mat),
  Hexp = Hs,
  Hobs = Ho
)

head(heterozygosity_df)

```

